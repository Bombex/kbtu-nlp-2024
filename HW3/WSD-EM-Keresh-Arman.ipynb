{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff686fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import senseval\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2897d3d9-62fb-456c-b385-3de563b01fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package senseval to\n",
      "[nltk_data]     /Users/akeresh/nltk_data...\n",
      "[nltk_data]   Package senseval is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/akeresh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/akeresh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('senseval')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba46099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_senseval2_data(word):\n",
    "    \"\"\"\n",
    "    Load Senseval-2 instances for a given word.\n",
    "    :param word: The word to load instances for (e.g., 'hard.pos', 'interest.pos', 'line.pos', etc.)\n",
    "    :return: List of instances for the specified word.\n",
    "    \"\"\"\n",
    "    instances = senseval.instances(word)\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff3a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_senseval_data(data_entries):\n",
    "    \"\"\"\n",
    "    Enhance a collection of Senseval-2 data entries by including POS tagging and creating feature sets.\n",
    "    \n",
    "    :param data_entries: A collection of Senseval-2 data entries.\n",
    "    :return: An enhanced list of data entries with added linguistic features.\n",
    "    \"\"\"\n",
    "    def enhance_entry(entry):\n",
    "        extracted_words = [word_data[0] if isinstance(word_data, tuple) else word_data for word_data in entry.context]\n",
    "        tokenized_context = word_tokenize(' '.join(extracted_words))\n",
    "        \n",
    "        key_word = extracted_words[entry.position]\n",
    "        key_word_index = tokenized_context.index(key_word)  \n",
    "        \n",
    "        tagged_tokens = pos_tag(tokenized_context)\n",
    "        \n",
    "        feature_set = {\n",
    "            'word': tokenized_context[key_word_index],\n",
    "            'pos': tagged_tokens[key_word_index][1],\n",
    "            'prev_word_pos': tagged_tokens[key_word_index - 1][1] if key_word_index > 0 else 'START',\n",
    "            'next_word_pos': tagged_tokens[key_word_index + 1][1] if key_word_index < len(tokenized_context) - 1 else 'END',\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'features': feature_set,\n",
    "            'senses': entry.senses\n",
    "        }\n",
    "    \n",
    "    return [enhance_entry(entry) for entry in data_entries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3724266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed instances for hard.pos: 4333\n",
      "Example processed instance: {'features': {'word': 'hard', 'pos': 'JJ', 'prev_word_pos': 'VBZ', 'next_word_pos': 'TO'}, 'senses': ('HARD1',)}\n",
      "==========================================\n",
      "Number of processed instances for line.pos: 4146\n",
      "Example processed instance: {'features': {'word': 'lines', 'pos': 'NNS', 'prev_word_pos': 'NN', 'next_word_pos': 'IN'}, 'senses': ('cord',)}\n",
      "==========================================\n",
      "Number of processed instances for serve.pos: 4378\n",
      "Example processed instance: {'features': {'word': 'serve', 'pos': 'VB', 'prev_word_pos': 'TO', 'next_word_pos': 'PRP'}, 'senses': ('SERVE10',)}\n",
      "==========================================\n",
      "Number of processed instances for interest.pos: 2368\n",
      "Example processed instance: {'features': {'word': 'interest', 'pos': 'NN', 'prev_word_pos': 'IN', 'next_word_pos': 'NNS'}, 'senses': ('interest_6',)}\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "words = ['hard.pos','line.pos','serve.pos','interest.pos']\n",
    "for word in words:\n",
    "    instances = load_senseval2_data(word)\n",
    "    processed_instances = refine_senseval_data(instances)\n",
    "    \n",
    "    # Displaying the number of processed instances and a single instance example\n",
    "    print(f\"Number of processed instances for {word}: {len(processed_instances)}\")\n",
    "    print(\"Example processed instance:\", processed_instances[0])\n",
    "    print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04044b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interest_6': 0.5287162162162162,\n",
       " 'interest_5': 0.21114864864864866,\n",
       " 'interest_4': 0.07516891891891891,\n",
       " 'interest_1': 0.15244932432432431,\n",
       " 'interest_3': 0.02787162162162162,\n",
       " 'interest_2': 0.0046452702702702705}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_sense_frequencies(instances):\n",
    "    \"\"\"\n",
    "    Computes the probability of each sense occurring in a list of processed instances.\n",
    "    \n",
    "    :param instances: A list of processed instances, each containing 'senses'.\n",
    "    :return: A dictionary with senses as keys and their probabilities as values.\n",
    "    \"\"\"\n",
    "    sense_frequency = {}\n",
    "    total_sense_occurrences = 0\n",
    "    \n",
    "    for instance in instances:\n",
    "        senses = instance['senses']\n",
    "        for sense in senses:\n",
    "            if sense not in sense_frequency:\n",
    "                sense_frequency[sense] = 1\n",
    "            else:\n",
    "                sense_frequency[sense] += 1\n",
    "            total_sense_occurrences += 1\n",
    "    \n",
    "\n",
    "    sense_probabilities = {sense: frequency / total_sense_occurrences for sense, frequency in sense_frequency.items()}\n",
    "    \n",
    "    return sense_probabilities\n",
    "\n",
    "sense_probabilities = compute_sense_frequencies(processed_instances)\n",
    "sense_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd3ce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interest_6': {'word': 0.25,\n",
       "  'pos': 0.25,\n",
       "  'prev_word_pos': 0.25,\n",
       "  'next_word_pos': 0.25},\n",
       " 'interest_5': {'word': 0.25,\n",
       "  'pos': 0.25,\n",
       "  'prev_word_pos': 0.25,\n",
       "  'next_word_pos': 0.25},\n",
       " 'interest_4': {'word': 0.25,\n",
       "  'pos': 0.25,\n",
       "  'prev_word_pos': 0.25,\n",
       "  'next_word_pos': 0.25},\n",
       " 'interest_1': {'word': 0.25,\n",
       "  'pos': 0.25,\n",
       "  'prev_word_pos': 0.25,\n",
       "  'next_word_pos': 0.25},\n",
       " 'interest_3': {'word': 0.25,\n",
       "  'pos': 0.25,\n",
       "  'prev_word_pos': 0.25,\n",
       "  'next_word_pos': 0.25},\n",
       " 'interest_2': {'word': 0.25,\n",
       "  'pos': 0.25,\n",
       "  'prev_word_pos': 0.25,\n",
       "  'next_word_pos': 0.25}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_probabilities_of_features_by_sense(processed_data):\n",
    "    sense_to_feature_counts = {}\n",
    "    sense_to_total_counts = {}\n",
    "\n",
    "    for item in processed_data:\n",
    "        for sense in item['senses']:\n",
    "            if sense not in sense_to_feature_counts:\n",
    "                sense_to_feature_counts[sense] = {}\n",
    "            if sense not in sense_to_total_counts:\n",
    "                sense_to_total_counts[sense] = 0\n",
    "            \n",
    "            for feature, _ in item['features'].items():\n",
    "                if feature not in sense_to_feature_counts[sense]:\n",
    "                    sense_to_feature_counts[sense][feature] = 1\n",
    "                else:\n",
    "                    sense_to_feature_counts[sense][feature] += 1\n",
    "                \n",
    "                sense_to_total_counts[sense] += 1\n",
    "\n",
    "    probabilities = {}\n",
    "    for sense, features in sense_to_feature_counts.items():\n",
    "        probabilities[sense] = {}\n",
    "        for feature, count in features.items():\n",
    "            probabilities[sense][feature] = count / sense_to_total_counts[sense]\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "feature_given_sense_probabilities = compute_probabilities_of_features_by_sense(processed_instances)\n",
    "feature_given_sense_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae255d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f02862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_senseval_data(words):\n",
    "    \"\"\"\n",
    "    Load Senseval data for the specified words and preprocess it.\n",
    "    Returns a DataFrame with features and labels.\n",
    "    \"\"\"\n",
    "    data_frames = []\n",
    "    for word in words:\n",
    "        instances = senseval.instances(word)\n",
    "        processed_instances = refine_senseval_data(instances)\n",
    "        df = pd.DataFrame(processed_instances)\n",
    "        data_frames.append(df)\n",
    "    return pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a946277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = ['interest', 'line', 'serve']  # Example words\n",
    "words =  ['hard.pos','line.pos','serve.pos','interest.pos']\n",
    "data = load_and_prepare_senseval_data(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4b8bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'hard', 'pos': 'JJ', 'prev_word_pos': 'VBZ', 'next_word_pos': 'TO'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"features\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1205a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       HARD1       0.85      0.98      0.91       687\n",
      "       HARD2       0.58      0.36      0.44       105\n",
      "       HARD3       0.55      0.14      0.22        86\n",
      "     SERVE10       0.77      0.86      0.81       380\n",
      "     SERVE12       0.67      0.70      0.69       268\n",
      "      SERVE2       0.52      0.39      0.44       175\n",
      "      SERVE6       0.54      0.46      0.50        85\n",
      "        cord       0.26      0.14      0.19        63\n",
      "    division       0.56      0.06      0.11        82\n",
      "   formation       0.63      0.22      0.33        76\n",
      "  interest_1       0.47      0.69      0.56        55\n",
      "  interest_2       0.00      0.00      0.00         3\n",
      "  interest_3       0.00      0.00      0.00        12\n",
      "  interest_4       0.50      0.30      0.38        33\n",
      "  interest_5       0.72      0.74      0.73        88\n",
      "  interest_6       0.91      0.92      0.91       240\n",
      "       phone       0.32      0.08      0.13        85\n",
      "     product       0.60      0.95      0.73       448\n",
      "        text       0.32      0.11      0.16        74\n",
      "\n",
      "    accuracy                           0.71      3045\n",
      "   macro avg       0.51      0.43      0.43      3045\n",
      "weighted avg       0.67      0.71      0.67      3045\n",
      "\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_model(data):\n",
    "    X = data['features']\n",
    "    y = data['senses'].map(lambda x: x[0])\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('dict_vectorizer', DictVectorizer(sparse=False)),  \n",
    "        ('classifier', LogisticRegression(solver='liblinear'))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.inverse_transform(range(len(le.classes_))), zero_division=0))\n",
    "\n",
    "    print(\"==========================================\")\n",
    "\n",
    "train_and_evaluate_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16458c32",
   "metadata": {},
   "source": [
    "## The classification report \n",
    "\n",
    "Model excels at identifying certain classes (e.g., HARD1, product) with high precision, recall, and f1-scores, indicating strong performance in these areas. Conversely, it struggles with classes like interest_2 and interest_3, showing zero precision and recall, likely due to insufficient training examples or class imbalance. Other classes such as cord and division also present challenges, with low scores across the board, which might be due to the model's difficulty in distinguishing them from similar classes.\n",
    "\n",
    "The disparities in performance can be attributed to factors such as class imbalance, where some classes have significantly more examples than others, and limitations in feature representation that may not capture all nuances necessary for accurate classification across different senses. Additionally, the choice of model and its complexity may not be fully suited to the task's requirements.\n",
    "\n",
    "Improving the model could involve addressing class imbalance through techniques like oversampling or undersampling, enhancing feature engineering to capture more contextual information, experimenting with more sophisticated models better suited for text classification, and tuning hyperparameters to optimize performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
